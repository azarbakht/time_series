---
title: 'ST565: Time Series HW6'
author: "Amirhosein \"Emerson\" Azarbakht <azarbaka@oregonstate.edu>"
output: pdf_document
layout: one-col

---

## Question 1

### The dataset bluebirdlite contains log sales and prices for the “lite” version of bluebird chips. Quantify the relationship between sales and price.

```{r, include=FALSE}
library(TSA)
data(bluebirdlite)
library(dplyr)
library(ggplot2)
library(forecast)
# install.packages("tidyr")
library(tidyr)
?bluebirdlite
```

```{r}
plot(bluebirdlite)
big_font <- theme_grey(base_size =  24)


attach(bluebirdlite)

fit_lm <- lm(log.sales ~ price + I(price^2), data = bluebirdlite)
summary(fit_lm)

qplot(log.sales, price, data = bluebirdlite) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, colour = "red") +
  geom_smooth(se = FALSE)  +
  big_font

# assumptions
# residuals versus covariates
sales_lm <- fortify(fit_lm)
qplot(price, .resid, data = sales_lm, geom= "line")
qplot(price^2, .resid, data = sales_lm)

# residuals versus fitted
qplot(.fitted, .resid, data = sales_lm)

# normality of residuals
qqnorm(sales_lm$.resid)
qqline(sales_lm$.resid)

# correlation of residuals
source(url("http://stat565.cwick.co.nz/code/get_acf.R")) # my code for examine_corr
examine_corr(residuals(fit_lm)) 
last_plot() + big_font
# AR (4)? violates regression assumptions

library(nlme)
gls_fit <- gls(log.sales ~ price + I(price^2), data = bluebirdlite,
    correlation = corARMA(p = 4), method = "ML")
summary(gls_fit)

# or
# arima_fit <- with(bluebirdlite, 
#   arima(log.sales, order = c(4, 0, 1), xreg = cbind(price, I(price^2))))
# arima_fit

# diagnostics
fit_lm$residuals <- residuals(gls_fit, type = "normalized")
bluebirdlite$fitted <- fitted(gls_fit)

examine_corr(fit_lm$residuals)

plot(bluebirdlite$fitted, gls_fit$residuals, data = bluebirdlite)

qqnorm(gls_fit$residuals)
qqline(gls_fit$residuals)

confint(gls_fit)
confint(fit_lm)
intervals(gls_fit)


#' It is estimated that an increase in price of 10 cents is associated with decrease in median sales of `r round(est, 2)` (95% CI `r round(ci[1], 2)` to `r round(ci[2], 2)`).

#' Interestingly, accounting for the correlation changes our estimate only slightly here. 
```

## Question 2

### In class we looked at modelling the relationship between mortality, temperature and particulate matter. Repeat the analysis but seasonally difference all three series first. Compare the results.

You can get the cmort, tempr and part times series with:

```{r}
library(ggplot2)
library(dplyr)
# install.packages("tidyr")
library(tidyr)
load(url("http://www.stat.pitt.edu/stoffer/tsa3/tsa3.rda"))
source(url("http://stat565.cwick.co.nz/code/fortify-ts.r"))
source(url("http://stat565.cwick.co.nz/code/get_acf.R")) # my code for examine_corr
big_font <- theme_grey(base_size =  24)

# mort <- c(rep(NA,52), diff(cmort, lag = 52))
# temp <- c(rep(NA,52), diff(tempr, lag = 52))
# part <- c(rep(NA,52), diff(part, lag = 52))

mort <- diff(cmort, lag = 52)
temp <- diff(tempr, lag = 52)
part <- diff(part, lag = 52)


mort <- data.frame(mortality = mort, part = part, temp = temp)
mort$time <- fortify(cmort)$time[53:508]
mort
head(mort)
qplot(time, value, data = gather(mort, variable, value, -time), geom = "line") +
  facet_grid(variable ~ ., scale = "free")

qplot(temp, mortality, data = mort)
qplot(part, mortality, data = mort)
qplot(temp, part, data = mort)

qplot(temp, mortality, data = mort) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, colour = "red") +
  geom_smooth(se = FALSE)  +
  big_font

qplot(part, mortality, data = mort) + geom_smooth(se = FALSE) + 
  big_font

mort <- mutate(mort, temp_sc = temp - mean(temp),
               temp_2 = temp_sc^2,
               time0 = time - min(time))

fit_lm <- lm(mortality ~ time0 + temp_sc + temp_2 + part, data = mort, na.action = na.omit)
summary(fit_lm)

# assumptions
# residuals versus covariates
mort_lm <- fortify(fit_lm)
qplot(time0, .resid, data = mort_lm, geom= "line")
qplot(temp_sc, .resid, data = mort_lm)
qplot(part, .resid, data = mort_lm)

# residuals versus fitted
qplot(.fitted, .resid, data = mort_lm)

# normality of residuals
qqnorm(mort_lm$.resid)
qqline(mort_lm$.resid)

# correlation of residuals
examine_corr(residuals(fit_lm)) 
last_plot() + big_font
# AR (2)? violates regression assumptions

# two ways to fit
library(nlme)
gls_fit <- gls(mortality ~ time0 + temp_sc + temp_2 + part, data = mort,
    correlation = corARMA(p = 15), method = "ML")
summary(gls_fit)

# or
# auto.arima(mort$mortality)

arima_fit <- with(mort, 
  arima(mortality, order = c(15, 0, 0), xreg = cbind(time0, temp_sc, temp_2, part)))
arima_fit

# diagnostics
mort$residuals <- residuals(gls_fit, type = "normalized")
mort$fitted <- fitted(gls_fit)

examine_corr(mort$residuals)

qplot(fitted, residuals, data = mort) + geom_hline(yintercept = 0)
qplot(time, residuals, data = mort) + geom_hline(yintercept = 0)
qplot(temp, residuals, data = mort) + geom_hline(yintercept = 0)
qplot(part, residuals, data = mort) + geom_hline(yintercept = 0)

qqnorm(mort$residuals)
qqline(mort$residuals)

confint(arima_fit)
confint(fit_lm)
intervals(gls_fit)

# if you refit the model with white noise errors using gls, you can actually 
# test to see if the correlation structure improved the fit
gls_wn <- gls(mortality ~ time0 + temp_sc + temp_2 + part, data = mort, method = "ML")
anova(gls_wn, gls_fit)

# plot prediction on temp versus mortality plot
mort$pred <- predict(gls_fit, newdata = 
  data.frame(time0 = 0, temp_sc = mort$temp_sc,
             temp_2 = mort$temp_2, part = mean(mort$part)))

qplot(temp, mortality, data = mort) +
  geom_line(aes(y = pred))

```
